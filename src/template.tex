\documentclass[
    9pt,
    aspectratio=169,
]{beamer}

\graphicspath{{./media/}{./}}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmic}

\usetheme{Madrid} 
\definecolor{myRed}{RGB}{170, 0, 0}
\definecolor{myOrange}{RGB}{13,56,98}

\setbeamercolor*{structure}{bg=myRed!20,fg=myRed!90}

\setbeamercolor*{palette primary}{use=structure,fg=white,bg=structure.fg}
\setbeamercolor*{palette secondary}{use=structure,fg=myRed,bg=white}
\setbeamercolor*{palette tertiary}{use=structure,fg=white,bg=myRed} 

\setbeamercolor{frametitle}{bg=myRed!85,fg=white}

\setbeamercolor*{titlelike}{parent=palette primary}

\setbeamercolor{section in head/foot}{fg=myOrange, bg=white}

\setbeamercolor{item projected}{bg=myOrange}
\setbeamertemplate{enumerate items}{bg=myOrange}

\setbeamercolor{itemize item}{fg=myOrange}
\setbeamercolor{itemize subitem}{fg=myOrange}

\setbeamercolor{button}{bg=myOrange}

\setbeamercolor{section in toc}{fg=black}
\setbeamercolor{subsection in toc}{fg=black}

\setbeamercolor{block title}{bg=myOrange, fg=white}
\setbeamercolor{block body}{bg=myOrange!20}

\usefonttheme{serif}
\usepackage{palatino}
\usepackage[default]{opensans}
\useinnertheme{circles}

\useoutertheme{miniframes}

\title[Tensor Core Optimization]{Leveraging Tensor Core Architecture for Mixed-Precision Neural Network Inference}
\subtitle[Quantization Effects]{Quantitative Analysis of INT8/FP16 Throughput-Accuracy Tradeoffs}
\author[Karan Handa]{Karan Handa}

\institute[]{Department of Computer Science, Ashoka University}

\logo{\includegraphics[width=2cm]{ashoka.png}}

\begin{document}

\begin{frame}
\titlepage
\end{frame}

\section{Introduction}

\begin{frame}
\frametitle{Introduction \& Background}
\begin{columns}
\column{0.4\textwidth}
\begin{itemize}
    \item \textbf{Tensor Cores:} Specialized hardware units for matrix operations
    \item \textbf{Mixed Precision:} Combines FP16/INT8 computation with FP32 accumulation
    \item \textbf{Key equation:} $\mathbf{D} = \mathbf{A} \cdot \mathbf{B} + \mathbf{C}$ \quad \text{where } $\mathbf{A} \in \mathbb{R}^{m \times k}, \mathbf{B} \in \mathbb{R}^{k \times n}, \mathbf{C}, \mathbf{D} \in \mathbb{R}^{m \times n}$
\end{itemize}

\column{0.4\textwidth}
\begin{block}{Literature Highlights}
    \begin{itemize}
        \item NVIDIA's work on Tensor Core architecture (2018)
        \item Microsoft's ZeroQuant quantization framework
        \item Current SOTA: 4-bit quantization with 0.5\% accuracy loss
    \end{itemize}
\end{block}

\begin{align}
    \text{Speedup} = \frac{T_{\text{FP32}}}{T_{\text{INT8}}} \approx 2\text{-}4\times
\end{align}

\end{columns}
\end{frame}

\section{Conclusion}

\begin{frame}
\frametitle{Conclusion \& Future Work}
\begin{block}{Key Contributions}
    \begin{itemize}
        \item Main achievement 1
        \item Main achievement 2
        \item Main achievement 3
    \end{itemize}
\end{block}

\begin{block}{Future Directions}
    \begin{itemize}
        \item Potential improvement 1
        \item Extension opportunity 1
    \end{itemize}
\end{block}

\begin{center}
\vspace{0.5cm}
\Large Thank you!
\end{center}
\end{frame}

\end{document} 